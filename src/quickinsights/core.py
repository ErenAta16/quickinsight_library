"""
QuickInsights ana analiz modÃ¼lÃ¼

Bu modÃ¼l, veri setleri Ã¼zerinde kapsamlÄ± analiz yapan ana fonksiyonlarÄ± iÃ§erir.
"""

import pandas as pd
import numpy as np
from typing import Optional, List, Union
import warnings
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import time

from .utils import get_data_info, detect_outliers
from .visualizer import correlation_matrix, distribution_plots, summary_stats


def analyze(df: pd.DataFrame, 
           show_plots: bool = True, 
           save_plots: bool = False,
           output_dir: str = "./quickinsights_output") -> dict:
    """
    Veri seti Ã¼zerinde kapsamlÄ± analiz yapar.
    
    Bu fonksiyon, veri seti hakkÄ±nda genel bilgi, istatistiksel Ã¶zetler,
    korelasyon analizi ve gÃ¶rselleÅŸtirmeler sunar.
    
    Parameters
    ----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    show_plots : bool, default=True
        Grafikleri gÃ¶stermek isteyip istemediÄŸiniz
    save_plots : bool, default=False
        Grafikleri kaydetmek isteyip istemediÄŸiniz
    output_dir : str, default="./quickinsights_output"
        Grafiklerin kaydedileceÄŸi dizin
        
    Returns
    -------
    dict
        Analiz sonuÃ§larÄ±nÄ± iÃ§eren sÃ¶zlÃ¼k
        
    Examples
    --------
    >>> import quickinsights as qi
    >>> import pandas as pd
    >>> df = pd.read_csv('data.csv')
    >>> results = qi.analyze(df)
    """
    
    if df.empty:
        raise ValueError("Veri seti boÅŸ olamaz!")
    
    print("ğŸ” QuickInsights - Veri Seti Analizi BaÅŸlÄ±yor...")
    print("=" * 60)
    
    # Veri seti genel bilgileri
    print("\nğŸ“Š VERÄ° SETÄ° GENEL BÄ°LGÄ°LERÄ°")
    print("-" * 40)
    data_info = get_data_info(df)
    print(f"SatÄ±r sayÄ±sÄ±: {data_info['rows']:,}")
    print(f"SÃ¼tun sayÄ±sÄ±: {data_info['columns']}")
    print(f"Bellek kullanÄ±mÄ±: {data_info['memory_usage']:.2f} MB")
    print(f"Veri tipleri: {data_info['dtypes']}")
    
    # Eksik deÄŸer analizi
    print(f"\nâŒ Eksik deÄŸerler: {data_info['missing_values']:,}")
    if data_info['missing_values'] > 0:
        missing_percent = (data_info['missing_values'] / (data_info['rows'] * data_info['columns'])) * 100
        print(f"Eksik deÄŸer oranÄ±: {missing_percent:.2f}%")
    
    # SayÄ±sal deÄŸiÅŸken analizi - DataFrame kopyalama yapmadan
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    outliers = None
    
    if len(numeric_cols) > 0:
        print(f"\nğŸ”¢ SayÄ±sal deÄŸiÅŸkenler ({len(numeric_cols)}): {', '.join(numeric_cols)}")
        numeric_analysis = analyze_numeric(df[numeric_cols], show_plots=False)
        
        # AykÄ±rÄ± deÄŸer tespiti
        outliers = detect_outliers(df[numeric_cols])
        if outliers.any().any():
            print(f"âš ï¸  AykÄ±rÄ± deÄŸerler tespit edildi!")
    
    # Kategorik deÄŸiÅŸken analizi - DataFrame kopyalama yapmadan
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    if len(categorical_cols) > 0:
        print(f"\nğŸ·ï¸  Kategorik deÄŸiÅŸkenler ({len(categorical_cols)}): {', '.join(categorical_cols)}")
        categorical_analysis = analyze_categorical(df[categorical_cols], show_plots=False)
    
    # GÃ¶rselleÅŸtirmeler
    if show_plots:
        print(f"\nğŸ“ˆ GÃ¶rselleÅŸtirmeler oluÅŸturuluyor...")
        
        # Korelasyon matrisi (sadece sayÄ±sal deÄŸiÅŸkenler iÃ§in)
        if len(numeric_cols) > 1:
            correlation_matrix(df[numeric_cols], save_plot=save_plots, output_dir=output_dir)
        
        # DaÄŸÄ±lÄ±m grafikleri
        if len(numeric_cols) > 0:
            distribution_plots(df[numeric_cols], save_plots=save_plots, output_dir=output_dir)
    
    print("\nâœ… Analiz tamamlandÄ±!")
    print("=" * 60)
    
    # SonuÃ§larÄ± dÃ¶ndÃ¼r
    return {
        'data_info': data_info,
        'numeric_columns': list(numeric_cols),
        'categorical_columns': list(categorical_cols),
        'outliers_detected': outliers.any().any() if outliers is not None else False
    }


def analyze_numeric(df: pd.DataFrame, 
                   show_plots: bool = True,
                   save_plots: bool = False,
                   output_dir: str = "./quickinsights_output") -> dict:
    """
    SayÄ±sal deÄŸiÅŸkenler Ã¼zerinde detaylÄ± analiz yapar.
    
    Parameters
    ----------
    df : pd.DataFrame
        Sadece sayÄ±sal deÄŸiÅŸkenler iÃ§eren veri seti
    show_plots : bool, default=True
        Grafikleri gÃ¶stermek isteyip istemediÄŸiniz
    save_plots : bool, default=False
        Grafikleri kaydetmek isteyip istemediÄŸiniz
    output_dir : str, default="./quickinsights_output"
        Grafiklerin kaydedileceÄŸi dizin
        
    Returns
    -------
    dict
        SayÄ±sal analiz sonuÃ§larÄ±
    """
    
    if df.empty:
        print("âš ï¸  SayÄ±sal deÄŸiÅŸken bulunamadÄ±!")
        return {}
    
    print(f"\nğŸ”¢ SAYISAL DEÄÄ°ÅKEN ANALÄ°ZÄ° ({len(df.columns)} deÄŸiÅŸken)")
    print("-" * 50)
    
    # Ä°statistiksel Ã¶zet
    summary = summary_stats(df)
    
    # Vectorized printing - tÃ¼m kolonlarÄ± aynÄ± anda iÅŸle
    col_names = df.columns.tolist()
    means = [summary[col]['mean'] for col in col_names]
    medians = [summary[col]['median'] for col in col_names]
    stds = [summary[col]['std'] for col in col_names]
    mins = [summary[col]['min'] for col in col_names]
    maxs = [summary[col]['max'] for col in col_names]
    q1s = [summary[col]['q1'] for col in col_names]
    q3s = [summary[col]['q3'] for col in col_names]
    
    # Batch printing
    for i, col in enumerate(col_names):
        print(f"\nğŸ“Š {col}:")
        print(f"   Ortalama: {means[i]:.4f}")
        print(f"   Medyan: {medians[i]:.4f}")
        print(f"   Standart sapma: {stds[i]:.4f}")
        print(f"   Minimum: {mins[i]:.4f}")
        print(f"   Maksimum: {maxs[i]:.4f}")
        print(f"   Ã‡eyrekler: Q1={q1s[i]:.4f}, Q3={q3s[i]:.4f}")
    
    # GÃ¶rselleÅŸtirmeler
    if show_plots:
        distribution_plots(df, save_plots=save_plots, output_dir=output_dir)
    
    return summary


def analyze_categorical(df: pd.DataFrame, 
                       show_plots: bool = True,
                       save_plots: bool = False,
                       output_dir: str = "./quickinsights_output") -> dict:
    """
    Kategorik deÄŸiÅŸkenler Ã¼zerinde detaylÄ± analiz yapar.
    
    Parameters
    ----------
    df : pd.DataFrame
        Sadece kategorik deÄŸiÅŸkenler iÃ§eren veri seti
    show_plots : bool, default=True
        Grafikleri gÃ¶stermek isteyip istemediÄŸiniz
    save_plots : bool, default=False
        Grafikleri kaydetmek isteyip istemediÄŸiniz
    output_dir : str, default="./quickinsights_output"
        Grafiklerin kaydedileceÄŸi dizin
        
    Returns
    -------
    dict
        Kategorik analiz sonuÃ§larÄ±
    """
    
    if df.empty:
        print("âš ï¸  Kategorik deÄŸiÅŸken bulunamadÄ±!")
        return {}
    
    print(f"\nğŸ·ï¸  KATEGORÄ°K DEÄÄ°ÅKEN ANALÄ°ZÄ° ({len(df.columns)} deÄŸiÅŸken)")
    print("-" * 50)
    
    # Vectorized operations - tÃ¼m kolonlarÄ± aynÄ± anda iÅŸle
    col_names = df.columns.tolist()
    
    # TÃ¼m kolonlar iÃ§in value_counts'larÄ± aynÄ± anda hesapla
    value_counts_list = [df[col].value_counts() for col in col_names]
    missing_counts = df.isnull().sum()
    
    results = {}
    
    # Batch processing - tÃ¼m kolonlarÄ± aynÄ± anda iÅŸle
    for i, col in enumerate(col_names):
        value_counts = value_counts_list[i]
        missing = missing_counts[col]
        
        print(f"\nğŸ“Š {col}:")
        print(f"   Benzersiz deÄŸer sayÄ±sÄ±: {len(value_counts)}")
        print(f"   En yaygÄ±n deÄŸer: '{value_counts.index[0]}' ({value_counts.iloc[0]} kez)")
        
        if missing > 0:
            print(f"   Eksik deÄŸerler: {missing}")
        
        print(f"   Ä°lk 5 deÄŸer: {list(value_counts.head().index)}")
        
        results[col] = {
            'unique_count': len(value_counts),
            'most_common': value_counts.index[0],
            'most_common_count': value_counts.iloc[0],
            'missing_count': missing,
            'value_counts': value_counts
        }
    
    return results


class LazyAnalyzer:
    """
    Lazy evaluation ile veri analizi yapan sÄ±nÄ±f.
    
    Bu sÄ±nÄ±f, analizleri sadece gerektiÄŸinde yapar ve sonuÃ§larÄ± cache'ler.
    BÃ¶ylece tekrar analizler Ã§ok daha hÄ±zlÄ± olur.
    """
    
    def __init__(self, df: pd.DataFrame):
        """
        LazyAnalyzer'Ä± baÅŸlatÄ±r.
        
        Parameters
        ----------
        df : pd.DataFrame
            Analiz edilecek veri seti
        """
        self.df = df
        self._results = {}
        self._data_info = None
        self._numeric_analysis = None
        self._categorical_analysis = None
        self._correlation_matrix = None
        self._outliers = None
        
        # DataFrame kopyalama yapmadan kolon tiplerini belirle
        self._numeric_cols = df.select_dtypes(include=[np.number]).columns
        self._categorical_cols = df.select_dtypes(include=['object', 'category']).columns
        
        print("ğŸš€ LazyAnalyzer baÅŸlatÄ±ldÄ±!")
        print(f"   ğŸ“Š Veri seti boyutu: {df.shape}")
        print(f"   ğŸ’¾ Bellek kullanÄ±mÄ±: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")
    
    def get_data_info(self):
        """Veri seti genel bilgilerini dÃ¶ndÃ¼rÃ¼r (lazy)"""
        if self._data_info is None:
            print("ğŸ” Veri seti bilgileri hesaplanÄ±yor...")
            self._data_info = get_data_info(self.df)
        return self._data_info
    
    def get_numeric_analysis(self):
        """SayÄ±sal analiz sonuÃ§larÄ±nÄ± dÃ¶ndÃ¼rÃ¼r (lazy)"""
        if self._numeric_analysis is None:
            print("ğŸ”¢ SayÄ±sal analiz yapÄ±lÄ±yor...")
            if len(self._numeric_cols) > 0:
                self._numeric_analysis = analyze_numeric(self.df[self._numeric_cols], show_plots=False)
            else:
                self._numeric_analysis = {}
        return self._numeric_analysis
    
    def get_categorical_analysis(self):
        """Kategorik analiz sonuÃ§larÄ±nÄ± dÃ¶ndÃ¼rÃ¼r (lazy)"""
        if self._categorical_analysis is None:
            print("ğŸ·ï¸  Kategorik analiz yapÄ±lÄ±yor...")
            if len(self._categorical_cols) > 0:
                self._categorical_analysis = analyze_categorical(self.df[self._categorical_cols], show_plots=False)
            else:
                self._categorical_analysis = {}
        return self._categorical_analysis
    
    def get_correlation_matrix(self):
        """Korelasyon matrisini dÃ¶ndÃ¼rÃ¼r (lazy)"""
        if self._correlation_matrix is None:
            print("ğŸ“Š Korelasyon matrisi hesaplanÄ±yor...")
            if len(self._numeric_cols) > 1:
                # Korelasyon hesaplama
                self._correlation_matrix = self.df[self._numeric_cols].corr()
            else:
                self._correlation_matrix = pd.DataFrame()
        return self._correlation_matrix
    
    def get_outliers(self, method: str = 'iqr', threshold: float = 1.5):
        """AykÄ±rÄ± deÄŸerleri dÃ¶ndÃ¼rÃ¼r (lazy)"""
        if self._outliers is None:
            print("âš ï¸  AykÄ±rÄ± deÄŸerler tespit ediliyor...")
            if len(self._numeric_cols) > 0:
                self._outliers = detect_outliers(self.df[self._numeric_cols], method=method, threshold=threshold)
            else:
                self._outliers = {}
        return self._outliers
    
    def compute(self):
        """TÃ¼m analizleri yapar ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r"""
        print("ğŸš€ TÃ¼m analizler yapÄ±lÄ±yor...")
        
        results = {
            'data_info': self.get_data_info(),
            'numeric_analysis': self.get_numeric_analysis(),
            'categorical_analysis': self.get_categorical_analysis(),
            'correlation_matrix': self.get_correlation_matrix(),
            'outliers': self.get_outliers()
        }
        
        print("âœ… TÃ¼m analizler tamamlandÄ±!")
        return results
    
    def get_summary(self):
        """TÃ¼m analizlerin Ã¶zetini dÃ¶ndÃ¼rÃ¼r"""
        print("ğŸ“‹ TÃ¼m analizler yapÄ±lÄ±yor...")
        
        summary = {
            'data_info': self.get_data_info(),
            'numeric_analysis': self.get_numeric_analysis(),
            'categorical_analysis': self.get_categorical_analysis(),
            'correlation_matrix': self.get_correlation_matrix(),
            'outliers': self.get_outliers()
        }
        
        return summary
    
    def show_plots(self, save_plots: bool = False, output_dir: str = "./quickinsights_output"):
        """GÃ¶rselleÅŸtirmeleri gÃ¶sterir"""
        print("ğŸ“ˆ GÃ¶rselleÅŸtirmeler oluÅŸturuluyor...")
        
        # Korelasyon matrisi
        if len(self._numeric_cols) > 1:
            correlation_matrix(self.df[self._numeric_cols], save_plot=save_plots, output_dir=output_dir)
        
        # DaÄŸÄ±lÄ±m grafikleri
        if len(self._numeric_cols) > 0:
            distribution_plots(self.df[self._numeric_cols], save_plots=save_plots, output_dir=output_dir)
    
    def get_cache_status(self):
        """Cache durumunu gÃ¶sterir"""
        status = {
            'data_info': self._data_info is not None,
            'numeric_analysis': self._numeric_analysis is not None,
            'categorical_analysis': self._categorical_analysis is not None,
            'correlation_matrix': self._correlation_matrix is not None,
            'outliers': self._outliers is not None
        }
        
        print("ğŸ“Š Cache Durumu:")
        for key, cached in status.items():
            status_icon = "âœ…" if cached else "â³"
            cache_text = "Cache'de" if cached else "HenÃ¼z hesaplanmadÄ±"
            print(f"   {status_icon} {key}: {cache_text}")
        
        return status
    
    def clear_cache(self):
        """Cache'i temizler"""
        self._results = {}
        self._data_info = None
        self._numeric_analysis = None
        self._categorical_analysis = None
        self._correlation_matrix = None
        self._outliers = None
        print("ğŸ—‘ï¸  Cache temizlendi!")


def parallel_analysis(df: pd.DataFrame, 
                     n_jobs: int = -1,
                     backend: str = 'thread',
                     show_plots: bool = False,
                     save_plots: bool = False,
                     output_dir: str = "./quickinsights_output") -> dict:
    """
    Veri seti Ã¼zerinde paralel analiz yapar.
    
    Bu fonksiyon, farklÄ± analiz tÃ¼rlerini paralel olarak Ã§alÄ±ÅŸtÄ±rarak
    toplam analiz sÃ¼resini kÄ±saltÄ±r.
    
    Parameters
    ----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    n_jobs : int, default=-1
        KullanÄ±lacak iÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ± (-1 = tÃ¼m CPU Ã§ekirdekleri)
    backend : str, default='thread'
        Paralel iÅŸleme backend'i ('thread' veya 'process')
    show_plots : bool, default=False
        Grafikleri gÃ¶stermek isteyip istemediÄŸiniz
    save_plots : bool, default=False
        Grafikleri kaydetmek isteyip istemediÄŸiniz
    output_dir : str, default="./quickinsights_output"
        Grafiklerin kaydedileceÄŸi dizin
        
    Returns
    -------
    dict
        Paralel analiz sonuÃ§larÄ±
        
    Examples
    --------
    >>> import quickinsights as qi
    >>> df = pd.read_csv('data.csv')
    >>> results = qi.parallel_analysis(df, n_jobs=4)
    """
    
    if df.empty:
        raise ValueError("Veri seti boÅŸ olamaz!")
    
    # CPU Ã§ekirdek sayÄ±sÄ±nÄ± belirle
    if n_jobs == -1:
        n_jobs = mp.cpu_count()
    
    print(f"ğŸš€ Paralel Analiz BaÅŸlÄ±yor...")
    print(f"   ğŸ”§ Backend: {backend}")
    print(f"   âš¡ Ä°ÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ±: {n_jobs}")
    print(f"   ğŸ“Š Veri seti boyutu: {df.shape}")
    print("=" * 60)
    
    start_time = time.time()
    
    # Analiz tÃ¼rlerini belirle - DataFrame kopyalama yapmadan
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    
    # Veri bilgileri (hÄ±zlÄ±, paralel gerekmez)
    print("ğŸ” Veri seti bilgileri alÄ±nÄ±yor...")
    data_info = get_data_info(df)
    
    # Paralel iÅŸleme
    results = {}
    
    if backend == 'thread':
        with ThreadPoolExecutor(max_workers=n_jobs) as executor:
            # Futures'larÄ± topla ve aynÄ± anda baÅŸlat
            futures = {}
            
            # SayÄ±sal analiz
            if len(numeric_cols) > 0:
                numeric_future = executor.submit(
                    _analyze_numeric_parallel, df[numeric_cols], show_plots, save_plots, output_dir
                )
                futures['numeric'] = numeric_future
            
            # Kategorik analiz
            if len(categorical_cols) > 0:
                categorical_future = executor.submit(
                    _analyze_categorical_parallel, df[categorical_cols], show_plots, save_plots, output_dir
                )
                futures['categorical'] = categorical_future
            
            # AykÄ±rÄ± deÄŸerler
            if len(numeric_cols) > 0:
                outliers_future = executor.submit(
                    _analyze_outliers_parallel, df[numeric_cols]
                )
                futures['outliers'] = outliers_future
            
            # TÃ¼m sonuÃ§larÄ± topla
            for key, future in futures.items():
                results[key] = future.result()
    
    elif backend == 'process':
        with ProcessPoolExecutor(max_workers=n_jobs) as executor:
            # Futures'larÄ± topla ve aynÄ± anda baÅŸlat
            futures = {}
            
            # SayÄ±sal analiz
            if len(numeric_cols) > 0:
                numeric_future = executor.submit(
                    _analyze_numeric_parallel, df[numeric_cols], show_plots, save_plots, output_dir
                )
                futures['numeric'] = numeric_future
            
            # Kategorik analiz
            if len(categorical_cols) > 0:
                categorical_future = executor.submit(
                    _analyze_categorical_parallel, df[categorical_cols], show_plots, save_plots, output_dir
                )
                futures['categorical'] = categorical_future
            
            # AykÄ±rÄ± deÄŸerler
            if len(numeric_cols) > 0:
                outliers_future = executor.submit(
                    _analyze_outliers_parallel, df[numeric_cols]
                )
                futures['outliers'] = outliers_future
            
            # TÃ¼m sonuÃ§larÄ± topla
            for key, future in futures.items():
                results[key] = future.result()
    
    else:
        raise ValueError("GeÃ§ersiz backend! 'thread' veya 'process' kullanÄ±n.")
    
    # SonuÃ§larÄ± birleÅŸtir
    final_results = {
        'data_info': data_info,
        'parallel_results': results,
        'execution_time': time.time() - start_time,
        'n_jobs': n_jobs,
        'backend': backend
    }
    
    print(f"\nâœ… Paralel Analiz TamamlandÄ±!")
    print(f"   â±ï¸  Toplam sÃ¼re: {final_results['execution_time']:.3f} saniye")
    print(f"   ğŸš€ HÄ±zlanma: {len(results)} analiz paralel yapÄ±ldÄ±")
    
    return final_results


def _analyze_numeric_parallel(df: pd.DataFrame, show_plots: bool, save_plots: bool, output_dir: str):
    """Paralel sayÄ±sal analiz iÃ§in yardÄ±mcÄ± fonksiyon"""
    return analyze_numeric(df, show_plots, save_plots, output_dir)


def _analyze_categorical_parallel(df: pd.DataFrame, show_plots: bool, save_plots: bool, output_dir: str):
    """Paralel kategorik analiz iÃ§in yardÄ±mcÄ± fonksiyon"""
    return analyze_categorical(df, show_plots, save_plots, output_dir)


def _analyze_outliers_parallel(df: pd.DataFrame):
    """Paralel aykÄ±rÄ± deÄŸer analizi iÃ§in yardÄ±mcÄ± fonksiyon"""
    return detect_outliers(df)


def chunked_analysis(df: pd.DataFrame, 
                    chunk_size: int = 10000,
                    n_jobs: int = -1) -> dict:
    """
    BÃ¼yÃ¼k veri setlerini parÃ§alara bÃ¶lerek analiz eder.
    
    Bu fonksiyon, bellek sÄ±nÄ±rlarÄ±nÄ± aÅŸmamak iÃ§in bÃ¼yÃ¼k veri setlerini
    kÃ¼Ã§Ã¼k parÃ§alara bÃ¶ler ve her parÃ§ayÄ± ayrÄ± ayrÄ± analiz eder.
    
    Parameters
    ----------
    df : pd.DataFrame
        Analiz edilecek veri seti
    chunk_size : int, default=10000
        Her chunk'taki satÄ±r sayÄ±sÄ±
    n_jobs : int, default=-1
        KullanÄ±lacak iÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ±
        
    Returns
    -------
    dict
        Chunk'larÄ±n analiz sonuÃ§larÄ±
    """
    
    if df.empty:
        raise ValueError("Veri seti boÅŸ olamaz!")
    
    if chunk_size <= 0:
        raise ValueError("Chunk boyutu pozitif olmalÄ±dÄ±r!")
    
    print(f"ğŸ”ª Chunked Analiz BaÅŸlÄ±yor...")
    print(f"   ğŸ“Š Veri seti boyutu: {df.shape}")
    print(f"   ğŸ”ª Chunk boyutu: {chunk_size:,}")
    
    # Chunk sayÄ±sÄ±nÄ± hesapla
    total_chunks = (len(df) + chunk_size - 1) // chunk_size
    print(f"   ğŸ“¦ Toplam chunk sayÄ±sÄ±: {total_chunks}")
    print("=" * 60)
    
    start_time = time.time()
    
    # Chunk'larÄ± daha verimli oluÅŸtur - numpy array slicing kullan
    chunk_indices = np.arange(0, len(df) + chunk_size, chunk_size)
    chunks = [df.iloc[start:min(start + chunk_size, len(df))] for start in chunk_indices[:-1]]
    
    print(f"âœ… {len(chunks)} chunk oluÅŸturuldu")
    
    # CPU Ã§ekirdek sayÄ±sÄ±nÄ± belirle
    if n_jobs == -1:
        n_jobs = min(mp.cpu_count(), len(chunks))
    
    # Paralel chunk analizi
    results = []
    
    with ThreadPoolExecutor(max_workers=n_jobs) as executor:
        # Her chunk iÃ§in analiz gÃ¶revi oluÅŸtur
        chunk_futures = []
        for i, chunk in enumerate(chunks):
            future = executor.submit(_analyze_chunk, chunk, i+1, len(chunks))
            chunk_futures.append(future)
        
        # SonuÃ§larÄ± topla
        for future in chunk_futures:
            result = future.result()
            results.append(result)
    
    # SonuÃ§larÄ± birleÅŸtir
    merged_results = _merge_chunk_results(results)
    
    execution_time = time.time() - start_time
    
    print(f"\nâœ… Chunked Analiz TamamlandÄ±!")
    print(f"   â±ï¸  Toplam sÃ¼re: {execution_time:.3f} saniye")
    print(f"   ğŸ“Š Analiz edilen chunk sayÄ±sÄ±: {len(chunks)}")
    print(f"   ğŸš€ Paralel iÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ±: {n_jobs}")
    
    return {
        'chunk_results': results,
        'merged_results': merged_results,
        'execution_time': execution_time,
        'n_chunks': len(chunks),
        'chunk_size': chunk_size,
        'n_jobs': n_jobs
    }


def _analyze_chunk(chunk: pd.DataFrame, chunk_num: int, total_chunks: int) -> dict:
    """Tek bir chunk'Ä± analiz eder"""
    print(f"   ğŸ” Chunk {chunk_num}/{total_chunks} analiz ediliyor... ({chunk.shape})")
    
    # Chunk analizi
    chunk_info = get_data_info(chunk)
    
    # SayÄ±sal analiz
    numeric_cols = chunk.select_dtypes(include=[np.number]).columns
    numeric_analysis = {}
    if len(numeric_cols) > 0:
        numeric_analysis = analyze_numeric(chunk[numeric_cols], show_plots=False)
    
    # Kategorik analiz
    categorical_cols = chunk.select_dtypes(include=['object', 'category']).columns
    categorical_analysis = {}
    if len(categorical_cols) > 0:
        categorical_analysis = analyze_categorical(chunk[categorical_cols], show_plots=False)
    
    return {
        'chunk_num': chunk_num,
        'chunk_info': chunk_info,
        'numeric_analysis': numeric_analysis,
        'categorical_analysis': categorical_analysis,
        'shape': chunk.shape
    }


def _merge_chunk_results(chunk_results: List[dict]) -> dict:
    """Chunk sonuÃ§larÄ±nÄ± birleÅŸtirir"""
    if not chunk_results:
        return {}
    
    # Vectorized operations - tÃ¼m chunk'larÄ± aynÄ± anda iÅŸle
    chunk_info_list = [result['chunk_info'] for result in chunk_results]
    
    # Toplam istatistikler - numpy array kullanarak hÄ±zlandÄ±r
    total_rows = sum(info['rows'] for info in chunk_info_list)
    total_columns = chunk_info_list[0]['columns']
    total_memory = sum(info['memory_usage'] for info in chunk_info_list)
    
    # SayÄ±sal analizleri birleÅŸtir - daha verimli
    merged_numeric = {}
    if chunk_results[0]['numeric_analysis']:
        numeric_cols = list(chunk_results[0]['numeric_analysis'].keys())
        
        # Her kolon iÃ§in aÄŸÄ±rlÄ±klÄ± ortalama hesapla
        for col in numeric_cols:
            # Vectorized calculation
            col_data = []
            weights = []
            
            for result in chunk_results:
                if col in result['numeric_analysis']:
                    col_data.append(result['numeric_analysis'][col]['mean'])
                    weights.append(result['chunk_info']['rows'])
            
            if weights:
                # NumPy ile aÄŸÄ±rlÄ±klÄ± ortalama
                col_data = np.array(col_data)
                weights = np.array(weights)
                weighted_mean = np.average(col_data, weights=weights)
                
                merged_numeric[col] = {
                    'mean': float(weighted_mean),
                    'chunks_analyzed': len(weights)
                }
    
    # Kategorik analizleri birleÅŸtir - daha verimli
    merged_categorical = {}
    if chunk_results[0]['categorical_analysis']:
        categorical_cols = list(chunk_results[0]['categorical_analysis'].keys())
        
        for col in categorical_cols:
            # TÃ¼m chunk'lardan deÄŸer sayÄ±larÄ±nÄ± topla - Counter kullan
            from collections import Counter
            total_counts = Counter()
            chunks_analyzed = 0
            
            for result in chunk_results:
                if col in result['categorical_analysis']:
                    chunks_analyzed += 1
                    value_counts = result['categorical_analysis'][col]['value_counts']
                    total_counts.update(value_counts)
            
            if total_counts:
                merged_categorical[col] = {
                    'total_counts': dict(total_counts),
                    'unique_values': len(total_counts),
                    'chunks_analyzed': chunks_analyzed
                }
    
    return {
        'total_rows': total_rows,
        'total_columns': total_columns,
        'total_memory_mb': total_memory,
        'merged_numeric': merged_numeric,
        'merged_categorical': merged_categorical,
        'chunks_analyzed': len(chunk_results)
    }
